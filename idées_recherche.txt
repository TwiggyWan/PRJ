1 fonctionnement d'une souris optique ->asservissement interne capteur hauteur + caméra du bas

http://en.wikipedia.org/wiki/Monte_Carlo_localization
http://en.wikipedia.org/wiki/Particle_filter

Caméra du bas donne des images de mauvaise qualité, il faudrait une phase de traitement de l'image en plus



2 Visual servoing
Présentation expliquant les bases de l'asservissement visuel
http://www.univ-orleans.fr/mapmo/jcont/Courtial.pdf

DYNAMICS & CONTROL TECHNOLOGY GROUP MOBILE ROBOT NAVIGATION USING VISUAL SERVOING
http://www.mate.tue.nl/mate/pdfs/11494.pdf

Visual servoing of an autonomous helicopter
http://eprints.qut.edu.au/8184/1/8184.pdf
asservissement de l'hélicoptère réalisé par une combinaison gyroscope/accéléromètre/asservissement visuel/gps
la partie visuelle sert à trouver des fenêtres et à s'aligner avec;
des algorithmes de détection de contour, de mise en gris des images, de filtrage sont mis en oeuvre;
idée intéressante : les algorithmes ne sont pas appliqués sur l'image en entier mais sur une portion de celle-ci;
la grosse partie de cet article traite de la détection de contours et du filtrage pour rendre
les données exploitables;
algorithme d'alignement : Lucas-Kanade;
l'altitude est gérée par un autre capteur : les déplacements à déduire des images sont dans le plan image uniquement;
but : minimiser l'angle (latéral donc) entre l'objectif d'alignement et l'endroit où pointe la caméra
de l'hélicoptère.
j'ai pas du tout compris les maths derrière cet algorithme.
qu'est ce qu'une fenêtre gaussienne?


Résumés sur les différentes méthodes d'asservissement visuel
http://dfolio.free.fr/wiki/Recherche/AsservissementVisuel
http://en.wikipedia.org/wiki/Visual_Servoing#Visual_Servoing_Methodology

Visual servo control part 1 : basic approaches
http://www.irisa.fr/lagadic/pdf/2006_ieee_ram_chaumette.pdf
Explication sur les deux types d'asservissement visuel : image based (IVBS) et position based (PVBS);
PVBS implique d'avoir des données 3D, loi de commande et modélisation spécifiques;
IVBS utilisable avec une ou plusieurs caméras;
utilise une matrice d'interaction 2/6 car 6 degrés de liberté;
en connaissant la focale de la caméra et le ratio des dimensions des pixels (?) 
on peut convertir les données de l'image (pixels) en données métriques;
cependant il faut impérativement connaître la profondeur, et un autre capteur doit être mis en place.
3 lois de commande différentes, l'une meilleure que les deux autres, calcul matriciel impliqué.

Visual servo control part 2 : advanced approaches
http://www.irisa.fr/lagadic/pdf/2007_ieee_ram_chaumette.pdf


vision based autonomous helicopter research
http://repository.cmu.edu/cgi/viewcontent.cgi?article=1020&context=robotics


visual odometry
http://en.wikipedia.org/wiki/Visual_odometry


shape from focus/defocus
http://sipl.kjist.ac.kr/about/SFF1.htm
Article reprenant la théorie derrière le concept

Shape from focus (Nayar 1994)
http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=308479&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D308479
Application à des images microscopiques
Possibilité de calculer des images defocused à partir d'une image focused en utilisant une "blurring function"
qui est faite à partir d'une fonction gaussienne à deux dimensions (???);
On fait une convolution entre cette fonction et l'image focused pour obtenir une image defocused (floue quoi)
Dans le domaine fréquentiel la transformée de fourier de la blurring function agit comme un filtre passe-bas
Obtenir des images floues avec le système optique : bouger l'objet/la caméra with respect to object plane
(=uniquement selon l'axe Z je suppose)
Plus on éloigne l'objet de la position de focus initiale, plus le flou dans les images augmente (logique jusque là)
Cependant, les auteurs ont développé un système de mesure du focus (mesure du flou) pour détecter le moment où 
l'image est la plus nette
En pratique, des images sont réalisées à intervalles de distance réguliers et on déduit le reste du comportement
de la netteté par interpolation; utilisation de l'opérateur Laplacien
Problème : il faut quand même pas mal d'images dans leurs exemples pour obtenir une courbe correcte (plus de 20)
Une fois qu'on connait la netteté d'une image et si on dispose d'une image parfaitement nette en référence, on 
peut estimer la profondeur de l'image floue par rapport à l'image nette



shape from shading
http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=784284&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D784284
